{"title": "Google wants to make sure AI advances don\u2019t leave anyone behind", "content": " \nFor every exciting opportunity promised by artificial intelligence, there\u2019s a potential downside that is its bleak mirror image. We hope that AI will allow us to make smarter decisions, but what if it ends up reinforcing the prejudices of society? We dream that technology might free us from work, but what if only the rich benefit, while the poor are dispossessed?\nIt\u2019s issues like these that keep artificial intelligence researchers up at night, and they\u2019re also the reason that Google is launching an AI initiative today to tackle some of these same problems. The new project is named PAIR (it stands for \u201cPeople + AI Research\u201d) and its aim is to \u201cstudy and redesign the ways people interact with AI systems\u201d and try to ensure that the technology \u201cbenefits and empowers everyone.\u201d \nGoogle wants to help everyone from coders to users\nIt\u2019s a broad remit, and an ambitious one. Google says PAIR will look at a number of different issues affecting everyone in the AI supply chain \u2014 from the researchers who code algorithms, to the professionals like doctors and farmers who are (or soon will be) using specialized AI tools. The tech giant says it wants to make AI user-friendly, and that means not only making the technology easy to understand (getting AI to explain itself is a known and challenging problem) but also ensuring that it treats its users equally.\nIt\u2019s been noted time and time again that the prejudices and inequalities of society often become hard-coded in AI. This might mean facial recognition software that doesn\u2019t recognize dark-skinned users, or a language processing program which assume that doctors are always male and nurses are always female. \nUsually this sort of issue is caused by the data that artificial intelligence is trained on. Either the information it has it incomplete, or it\u2019s prejudiced in some way. That\u2019s why PAIR\u2019s first real news is the announcement of two new open-source tools \u2014 called Facets Overview and Facets Dive \u2014 which make it easier for programmers to examine datasets. \n\n\n\n\n\n\n\n\nA screenshot of Facets Dive \u2014 an open-source tool for examining data used by AI.\nImage: Google / PAIR\n\n\nIn the screenshot above Facets Dive is being used to test a facial recognition system. The program is sorting the testers by their country of origin and comparing errors with successful identifications. This allows a coder to quickly see where their dataset is falling short, and make the relevant adjustments. \nCurrently, PAIR has 12 full-time staff. It\u2019s a bit of a small figure considering the scale of the problem, but Google says PAIR is really a company-wide initiative \u2014 one that will draw in expertise from the firm\u2019s various departments. \nMore open-source tools like Facets will be released in the future, and Google will also be setting up new grants and residencies to sponsor related research. It\u2019s not the only big organization taking these issues seriously (see also: the Ethics and Governance of Artificial Intelligence Fund and Elon Musk-funded OpenAI), but it\u2019s good to see Google join the fight for a fairer future. \n"}
