{"title": "Deep neural networks can now transfer the style of one photo onto another", "content": " \nYou\u2019ve probably heard of an AI technique known as \u201cstyle transfer\u201d \u2014 or, if you haven\u2019t heard of it, you\u2019ve seen it. The process uses neural networks to apply the look and feel of one image to another, and appears in apps like Prisma and Facebook. These style transfers, however, are stylistic, not photorealistic. They look good because they look like they\u2019ve been painted. Now a group of researchers from Cornell University and Adobe have augmented style transfer so that it can transfer the look of one photo onto another \u2014 while still looking like a photo. The results are impressive. \nThe researchers\u2019 work is outlined in a paper called \u201cDeep Photo Style Transfer.\u201d Essentially, they\u2019ve taken the methods of the original style transfer, and added another layer of neural networks to the process \u2014 a layer that makes sure that the details of the original image are preserved. \n\n\n\n\n\n\n\n\nFrom left to right: the original image, the reference image, and the output.\n\n\n\u201cPeople are very forgiving when they see [style transfer images] in these painterly styles,\u201d Cornell professor Kavita Bala, a co-author of the study, tells The Verge. \u201cBut with real photos there\u2019s a stronger expectation of what we want it to look like, and that\u2019s why it becomes an interesting challenge.\u201d \nThe added neural network layer pays close attention to what Bala calls \u201clocal affine patches.\u201d There\u2019s no quick way to accurately translate this phrase, but it basically means the various edges within the image, whether that\u2019s the border between a tree and a lake, or a building and the sky. While style transfer tends to play fast and loose with these edges, shifting them back and forth as it pleases, photo style transfer preserves them. \nThere are limits to the technique, of course. The algorithms seem to work best with structures like buildings \u2014 the flaws are more obvious with faces. And you can\u2019t use massively different photos for transferring style, otherwise the neural networks have a tougher time analyzing elements to copy from picture to picture. \u201cIf you have a picture of a lake and you have a scene where you\u2019re taking the style from, ideally it would also have a water body in it of some sort,\u201d says Bala. \u201cThere\u2019s no defined limit, but this is a good open research question. We put the code out because we want people to play with it and try it out.\u201d (The code is available here on GitHub.)\n\n\n\n\n\n\n\n\nIn the image marked Neural Style, you can see how ordinary style transfer mutates the sharp edges of the photo.\n\n\nThe question is, how long will it be until we start seeing these sorts of photo style transfers being made accessible to the public? After all, the original style transfer went from a first research paper to Facebook\u2019s app, reaching hundreds of millions of users, in  less than two years\u2019 time. And with Adobe\u2019s involvement in this paper, there\u2019s obviously an expectation that it\u2019s at least a little bit interested in some sort of commercialization. We\u2019ve reached out to the company to find out more, and will update if and when we hear back. \nFor now, though, the researchers are already thinking about what areas photorealistic style transfer could be applied to next. \u201cThe question of how far you can push it is important,\u201d says Bala. \u201cVideo is a logical thing for it to go to, and that, I expect, will happen.\u201d \n\n"}
