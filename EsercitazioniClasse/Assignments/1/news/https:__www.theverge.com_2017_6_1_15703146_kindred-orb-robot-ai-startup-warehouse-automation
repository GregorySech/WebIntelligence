{"title": "The next big leap in AI could come from warehouse robots", "content": " \nAsk Geordie Rose and Suzanne Gildert, co-founders of the startup Kindred, about their company\u2019s philosophy, and they\u2019ll describe a bold vision of the future: machines with human-level intelligence. Rose says these will be perhaps the most transformative inventions in history \u2014 and they aren\u2019t far away. More intriguing than this prediction is Kindred\u2019s proposed path for achieving it. Unlike some of the most cash-flush corporations in Silicon Valley, Kindred is focusing not on chatbots or game-playing programs, but on automating physical robots. \nGildert, a physicist who conceived Kindred in 2013 while working with Rose at quantum computing company D-Wave, thinks giving AI a physical body is the only way to make real progress toward a true thinking machine. \u201cIf you want to build intelligence that conceptually thinks in the same way a human does\u2026 it needs to have a similar sensory motor as humans do,\u201d Gildert says. The trick to achieving this, she thinks, is to train robots by having them collaborate with humans in the physical world. Rose, who co-founded D-Wave in 1999, stepped back from his role as chief technology officer to work on Kindred with Gildert. \nKindred wants to train robots by having them collaborate with humans in the physical world\nThe first step toward their new shared goal is an industrial warehouse robot called the Orb. It\u2019s a robotic arm that sits inside a hexagonal glass encasement, equipped with a bevy of sensors to help it see, feel, and even hear its surroundings. The arm is operated using a mix of human control and automated software. Because so many warehouse workers today spend a significant amount of time sorting products and scanning barcodes, Kindred developed a robotic arm that can do some elements automatically. Meanwhile, humans step in when needed to manually operate the robot to perform tasks that are difficult for machines, like gripping a single product from a cluster of different items. \nWorkers can even operate the arm remotely using an off-the-shelf HTC Vive headset and virtual reality motion controllers. It turns out that VR is great for gathering data on depth and other information humans intuitively use to grasp objects. \nKindred is now focused on getting its finished Orb into warehouses, where it can begin learning at an accelerated pace by sorting vastly different products and observing human operators. Because the company gathers data every time a human uses the Orb, engineers are able to improve its software over time using techniques such as reinforcement learning, which improves software through repetition. Down the line, the Orb should slowly take over more responsibility and, ideally, learn to perform new tasks.\nBut Kindred\u2019s ultimate goal is much more ambitious. It may sound counterintuitive, but Rose and Gildert think warehouses are the perfect place to start on the path toward human-level artificial intelligence. Because the US shipping marketplace is already rife with single-purpose robots, thanks in part to Amazon, there are plenty of opportunities for humans to train AI. Finding, handling, and sorting products while maneuvering in a fast-moving environment is a data gold mine for building robots that can operate in the real world. \nRose and Gildert believe the next generation of AI won\u2019t be in the form of a disembodied voice living in our phones. Rather, they believe the greatest strides will come from programs running inside a physical robot can gain knowledge about the world and itself from the ground up, like a human infant does from birth.  \n \n\n\n\n\n\n\n\nChris Hayes, a Kindred VR pilot and software engineer, operates the Orb remotely using a Vive headset in the company\u2019s San Francisco office. \n\n\n\nKindred\u2019s is working toward what\u2019s known as artificial general intelligence, or software capable of performing any task a human being can do. Artificial general intelligence, or AGI, is sometimes referred to as \u201cstrong\u201d or \u201cfull\u201d AI because it exists in contrast to AI programs, like DeepMind\u2019s AlphaGo system, with very specific applications. Other more conventional forms of \u201cweak\u201d or \u201cnarrow\u201d AI include the underlying software behind Netflix and Amazon recommendations, Snapchat camera effects that rely on facial recognition, and Google\u2019s fast and accurate language translations. \nThese algorithms are developed by applying deep learning techniques to large-scale neural networks until they can, say, differentiate between an image of a dog and a cat. They perform one task, or perhaps many in some cases, far better than humans can. But they are extremely limited and don\u2019t learn or adapt the way humans do. The software that recognizes a sunset can\u2019t predict whether you\u2019ll like a Netflix movie or translate a sentence into Japanese. Right now, you can\u2019t ask AlphaGo to face off in chess \u2014 it doesn\u2019t know the rules and wouldn\u2019t know how to begin learning them. \nKindred thinks our physical body is intrinsic to the secrets of human cognition\nThis is the fundamental challenge of AGI: how to create an intelligent system, the kind we know only from science fiction, that can truly learn on its own without needing to be fed thousands of examples and trained over the course of weeks or months.\nThe biggest names in AI research, like DeepMind, are focused on game-playing because it seems to be the most viable path forward. After all, if you can teach software to play Pong, perhaps it can take the lessons learned and apply them to Breakout? This applied knowledge approach, which mimics the way a human player can quickly intuit the rules of a new game, has proven promising. \nFor instance, AlphaGo Master, DeepMind\u2019s latest Go system that just bested world champion Ke Jie, now effectively teaches itself how to play better. \u201cOne of the things we\u2019re most excited about is not just that it can play Go better, but we hope that this\u2019ll actually lead to technologies that are more generally applicable to other challenging domains,\u201d DeepMind co-founder and CEO Demis Hassabis said at the event last week.\n\n\n\n\n\n\n\n\nGoogle-owned DeepMind is focusing on game-playing systems, like AlphaGo, to make progress toward a general purpose \u201cstrong\u201d AI. \n\n\nYet for Kindred\u2019s founders, the quest to crack the secret of human cognition can\u2019t be separated from our physical bodies. \u201cOur founding belief was that in order to make real progress toward the original objectives of AI, you needed to start by grounding your ideas in the physical world,\u201d Rose says. \u201cAnd that means robots, and robots with sensors that can look around, touch, hear the world that surrounds them.\u201d\nThis body-first approach to AI is based on a theory called embodied cognition, which suggests that the interplay between our brain, body, and the physical world is what produces elements of consciousness and the ability to reason. (A fun exercise here is thinking about how many common metaphors have physical underpinnings, like thinking of affection as warmth or something inconceivable as being \u201cover your head.\u201d) Without understanding how the brain developed to control the body and guide functions like locomotion and visual processing, the theory goes, we may never be able to reproduce it artificially. \nThe body-first approach to AI is based on a theory called embodied cognition\nOther than Kindred, work on AI and embodied cognition mostly happens in the research divisions of large tech companies and academia. For example, Pieter Abbeel, who leads development on the Berkeley Robot for the Elimination of Tedious Tasks (BRETT), aims to create robots that can learn much like young children do.\nBy giving its robot sensory abilities and motor functions and then using AI training techniques, the BRETT team devised a way for it to acquire knowledge and physical skills much faster than with standard programming \u2014 and with the flexibility to keep learning. Much like how babies are constantly adjusting their behavior when attempting something new, BRETT also approaches unique problems, fails at first, and then adjusts over repeated attempts and under new constraints. Abbeel\u2019s team even uses children\u2019s toys to test BRETT\u2019s aptitude for problem solving. \nOpenAI, the nonprofit funded by SpaceX and Tesla CEO Elon Musk, is working on both general purpose game-playing algorithms and robotics, under the notion that both avenues are complementary. Helping the team is Abbeel, who is on leave from Berkeley to help OpenAI make progress fusing AI learnings with modern robotics. \u201cThe interesting thing about robotics is that it forces us to deal with the actual data we would want an intelligent agent to deal with,\u201d says Josh Tobin, a graduate student at Berkeley who works on robotics at OpenAI. \nApplying AI to real-world tasks like picking up objects and stacking blocks involves tackling a whole suite of new problems, Tobin says, like managing unfamiliar textures and replicating minute motor movements. Solving them is necessary if we\u2019re to ever deploy intelligent robots beyond factory floors. \nWojciech Zaremba, who leads OpenAI\u2019s robotics work, says that a holy grail of sorts would be a general-purpose robot powered by AI that can learn a new task \u2014 scrambling eggs, for instance \u2014 by watching someone do it just once. This is why OpenAI is working on teaching robots new skills that are first demonstrated by a human in a simulated VR environment, much like a video game, where it\u2019s much easier and less costly to produce and collect data.\n\u201cYou could imagine that, as a final outcome, if it\u2019s doable, you have files online of recordings of various tasks,\u201d Zaremba says. \u201cAnd then if you want the robot to replicate this behavior, you just download the file.\u201d\n \n\n\n\n\n\n\n\nKindred\u2019s Orb is designed to automate the task of picking up and sorting products with help from human operators. \n\n\n\nWhen I first operated the Orb, on an April afternoon in Kindred\u2019s San Francisco warehouse space, a group of six or so engineers were scattered about testing the robotic arms with various pink-colored bins of products \u2014 vitamin bottles, soft plastic cylinders of Lysol cleaning wipes, rolls of paper towels.\nThe Orb is designed to help sort these objects in a large heap inside its glass container, while the arm sits affixed to the roof of the container. First, an operator wearing a VR headset moves the arm to a desired object, lowers the gripper, and adjusts the two clamps until a firm grip is established. Then the human can simply let go. Kindred has already automated the process of lifting the object in the air, scanning the barcode, and sorting it into the necessary bin. \nUsing the Orb resembles operating a video game version of a toy claw machine\n\u201cIn any gigantic warehouse, people have to walk around and pick up things,\u201d says George Babu, Kindred\u2019s chief product officer. \u201cThe most efficient way to do that is to pick up a whole bunch of different things at the same time. Those go to someplace where you have them separated. Our robot does that job in the middle.\u201d The idea is that warehouse workers can dump a bunch of products into the Orb, while a remote operator works with the robot to sort them. \nAmazon is working on something similar, and the company now holds an annual \u201cpicking\u201d challenge to spur development in industrial robotics that are capable of handling and sorting physical items. Kindred is quick to recognize Amazon\u2019s prowess in this department. \u201cIn the fulfillment world, Amazon uses a different set of approaches than all of the other fulfillment provisioners. They have the scale, the scope, and the know-how to implement end-to-end systems that are very effective at what they do,\u201d Rose says. But he thinks Amazon is likely to keep this technology to itself. \u201cThe advancements that Amazon makes toward doing this job well don\u2019t benefit all of their competitors.\u201d\n\n\n\n\n\n\n\n\nKindred has entirely automated the process of scanning barcodes and sorting items with the Orb. Gripping, however, is performed by human operators. \n\n\nKindred\u2019s system, on the other hand, is designed to integrate into existing warehouse tools. Last month, Kindred finished its first deployable devices, and it \u201ccreated more demand than we anticipated,\u201d according to Jim Liefer, Kindred\u2019s chief operating officer, though he won\u2019t disclose any initial customers.\nI was surprised when using the Orb, with a Vive headset, by just how much it resembles a video game. Think of a toy claw machine, where the second the clamp touches down on an object, the automated process takes over and the arm springs to life with an uncanny jerkiness. It makes sense, considering Kindred built its depth-sensing system using the game engine Unity. \nKindred imagines future versions of the Orb being affixed to sliding rails or bipedal roaming robots\nMax Bennett, Kindred\u2019s robotics product manager, says that the process is designed so that human warehouse workers can operate multiple Orbs simultaneously, gripping objects and letting the software take the reins before cycling to the next setup. Kindred imagines future versions of the robotic arm being affixed to sliding overhead rails or maybe even to bipedal robots that roam the floor. There is also a point at which the Vive is no longer necessary. \u201cNobody\u2019s going to want to use a VR headset all day,\u201d Bennett tells me, suggesting that an Xbox controller or even just a computer mouse will do in the future. \nAs for how the Orb might impact jobs, Babu says there will be need for human labor for quite some time. He\u2019s partly right: Amazon hired 100,000 workers in the last year alone, and plans to hire 100,000 more this year, mostly in warehouse and other fulfillment roles. But systems like the Orb raise the possibility that fewer jobs are needed as the work becomes more a matter of assisting and operating robots. \n\u201cMy view is that the humans will all move on to different work in the stream,\u201d Babu says.\nStill, Forrester Research predicts that automation will result in 25 million jobs lost over the next decade, with only 15 million new jobs created. The end goals of automation have always been to reduce costs and improve efficiency, and that will inevitably mean the disappearance of certain types of labor.\n \n\n\n\n\n\n\n\nKindred is split between its headquarters in Vancouver, a machine learning division in Toronto, and its robotics lab in San Francisco. \n\n\n\nKindred is unique in the AI field not just for its robotics focus, but also because it\u2019s diving head first into the industrial world with a commercial product. Many of the big tech companies working on AI are doing so with huge research organizations, like Facebook AI Research and Google Brain. These teams are filled with academics and engineers who work on abstract problems that then help inform real software features that get deployed to millions of consumers.\nKindred, as a startup, can\u2019t afford this approach. \u201cDay one we said: \u2018We\u2019re going to find a big market. We\u2019re going to build a wildly successful product for that initial market, and build a business by executing along that path first with one vertical and then maybe others,\u2019\u201d Rose explains. He adds that his experience with D-Wave, which raised more than $150 million over the course of more than a decade just to release its first product, inspired him to seek out a different approach to tackling big-picture problems. \nGildert and Rose don\u2019t want to rely solely on venture capital funding to build Kindred\n\u201cYou have this quandary that doing it right is going to take a long time, on the order of decades. How do you sustain that organization for that length of time without all the negative side effects of raising a lot of rounds of VC?\u201d Rose says. \u201cThe answer is that you have to create a real business that is cash-flow positive very early.\u201d Kindred has raised $15 million in funding thus far from Eclipse, GV, Data Collective, and a number of other investors. But Rose stresses that the company\u2019s focus is to become profitable with the Orb, and that will help it in its main objective. \nThat objective, since the beginning, is human-level AI with a focus on what Gildert calls \u201cin-body cognition,\u201d or the type of thought processes that only arise from giving AI a physical shell. \u201cIntelligence absence a body is not what we think it means,\u201d she says. \u201cIntelligence with a body brings to it a number of constraints that are not there when you think about intelligence in a virtual environment. We certainly don\u2019t believe you can build a chatbot without a human-like body and expect it to pass [for a human].\u201d  \n\u201cBrains evolved to control bodies,\u201d Rose adds. \u201cAnd all these things that we think about as being the beautiful stuff that comes from cognition, they\u2019re all side effects of this.\u201d\n\n"}
