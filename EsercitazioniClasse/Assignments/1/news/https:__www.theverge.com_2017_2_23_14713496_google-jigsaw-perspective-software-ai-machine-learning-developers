{"title": "Google just made its troll-detecting software available to developers", "content": " \nGoogle\u2019s Jigsaw unit, as part of a larger effort to battle online trolling, said earlier today that it was releasing a new tool called Perspective, based on software that uses machine learning to detect harassment and abuse online. \nWhile Jigsaw and its software are not new \u2014 the subsidiary has been around in some form since 2010, though with a different name, and Jigsaw software has even been used to spot potential ISIS recruits \u2014 this new Perspective API now makes it available to developers who want to use and build on top of the software. \nThe software works by determining the \u201ctoxicity\u201d of online comments, a scale that has been established by mining millions of comments from the web and then presenting them to panels of 10 people (humans!) at a clip to get their feedback. There\u2019s a demo version of the tool available on the Perspective API website, which anyone can use to type in a draft of their comments and get a sense of how toxic or abusive they might be (assuming one is thoughtful enough to go to the Perspective API website before they dash off their comment on an internet forum and leave a digital footprint for all of eternity). \nJigsaw\u2019s software isn\u2019t new, but now it\u2019s accessible to developers\nBut its real value may come from being plugged directly into popular comment sections on the web. Publishers like The New York Times, The Guardian, and the Economist are experimenting with the tool, according to this report in Wired, and plan to use it as a way to keep their comment sections a space where \u201ceveryone can have intelligent debates.\u201d\n\n\n\n\n\n\n\n\nCertain phrases or quotes that have worked their way into the mainstream in recent months register fairly high on the toxicity scale, according to the Perspective tool. \u201cFake news!\u201d registered as 47 percent similar to comments people said were \"toxic.\" \u201cBad hombre\u201d is 55 percent similar to comments people labeled as toxic. \u201cGrab her by the pussy\u201d was 92 percent similar. \nBut there also seem to be nuances that the tool isn\u2019t picking up, which may just be a part of the \u201clearning\u201d process of the machine learning. In the spirit of testing Perspective, I entered some of the remarks that were left on a recent YouTube video I did. \u201cHow about Verge allow a man to review the watch?\u201d someone wrote, which is blatantly sexist but only 3 percent similar to other toxic comments, according to Perspective. A negative comment about my appearance was only 6 percent similar to other negative remarks; it is somewhat reassuring that another YouTube comment, suggesting I have an eating disorder, was said to be 26 percent similar to other terrible remarks. \nWired\u2019s Andy Greenberg had similar results when he ran Jigsaw\u2019s software through its paces last fall, and pointed out that the \u201calgorithm still has lessons to learn.\u201d Which, apparently, is not too dissimilar from us humans. \nUpdate February 23rd, 1:45PM ET: Twitter user Ramsey Nasser points out that the algorithm has consistently high toxicity for Arabic, no matter the content.\n\n\nso i tried google's thing and anything in arabic seems to have a baseline 30% toxicity. these are direct translations. other languages? pic.twitter.com/UKGkiV0PHJ\u2014 Ramsey Nasser (@ra) February 23, 2017\n\n\n\n"}
