{"title": "Next Level: Inside Dolby\u2019s experiment to watch people while they\u2019re watching movies", "content": " \n \n\n\n\n\n\n\n\n\nThere are the smartphones and laptops we use every day, and then there\u2019s Next Level technology. In this new Verge video series, senior editor Lauren Goode takes you behind the scenes to show you the technology that\u2019s being worked on at some of the world\u2019s most innovative companies and research institutions. From modular airplanes to prescription video games to Hollywood\u2019s attempt to hack your emotions, Next Level will show you the technology that has the potential to radically change the way we interact with tech. \nDolby Laboratories has been around since 1965, and for most people, the company is synonymous to the white label you see at the end of movies that tells you that the sound and video have been remastered in some way. Inside its headquarters in San Francisco, Dolby has over a hundred technical labs, and over the past five years some of the labs have been devoted to a lesser-known project: watching people while they\u2019re watching movies. \n\n\n\n\n\n\n\n\nLed by neurophysiologist and Dolby chief scientist Poppy Crum, the company has been attaching biosensors to willing subjects and plopping them down on a couch to settle in for an entertainment session. Using EEG caps, heart rate monitors, galvanic skin response sensors, and thermal imaging Flir cameras, the scientists can observe the biophysical and emotional responses that humans are experiencing via media. They\u2019re trying to figure out what kind of videos and sounds make people\u2019s hearts race, what makes their skin flush, and what makes them cognitively engaged, aroused, or maybe even... bored.\nDolby wants to know what kind of content makes your skin flush, what makes you cognitively engaged, and what makes you aroused\nWhy would Dolby, of all companies, want to do this \u2014 especially since it isn\u2019t making video or audio content from scratch? Basically, it\u2019s using this information to better sell its own technology to its Hollywood content partners. The idea being that if it can prove that HDR, surround sound, or a certain color palette, will elicit an emotional response, then the creative content makers are more likely to want to use Dolby tools. This kind of affective computing has been around for decades, but industry experts say that in entertainment it\u2019s becoming even more common. Case in point: both Netflix and Hulu, already very data-driven companies, have used eye-tracking technology in recent years to get a sense of where people are looking within their app interfaces. \n\n\n\n\n\n\n\n\nFor this episode of Next Level, we went inside Dolby Labs to interview Crum and other Dolby executives. I also had the chance to sit in the lab and try on the biosensors myself. The data that I saw was raw, unprocessed data, so it was hard to tell exactly what the sensors were showing about me and my reactions. But it was easy to see how this kind of biophysical data would be imminently useful to the entertainment industry, and how movies and TV shows could be \u201chacked\u201d to trigger specific emotional responses.\n\n"}
