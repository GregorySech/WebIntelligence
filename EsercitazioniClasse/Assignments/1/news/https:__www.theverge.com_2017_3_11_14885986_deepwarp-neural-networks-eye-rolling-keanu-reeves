{"title": "You can use this machine learning demo to roll Keanu Reeves\u2019 (or anyone\u2019s) eyes", "content": " \nAnother day, another fun internet thing that uses neural networks for facial manipulation. This time it\u2019s DeepWarp, a demo created by Yaroslav Ganin, Daniil Kononenko, Diana Sungatullina, and Victor Lempitsky, that uses deep architecture to move human eyeballs in a still image. \nFirst spotted by Prosthetic Knowledge, DeepWarp is focused on realistic \u201cgaze manipulation.\u201d The authors of the demo acknowledge that similar projects already exist (like the smile-manipulator FaceApp), but without such a singular, detailed focus. \nThe authors note that their findings in this study could be applied to solve real-world issues of eye movement, like for \u201cgaze correction in video conferencing.\u201d It could also be useful for \u201ctalking head\u201d scenarios, when reliance on a teleprompter shifts a person\u2019s line of sight away from the camera. \nChanging Keanu\u2019s male gaze\nThe demo is available to try here. All you need to do is choose an image (horizontal seems to work best) featuring a person facing forward. After you upload that image, you can pick one of four eye-movement options, including roll and cross. DeepWarp will spit out an mp4 file of the resulting googly-eyed person. I tried this using images of Keanu Reeves and several dogs, but the demo didn\u2019t work with the dogs.\n\u201cOur system is reasonably robust against different head poses and deals correctly with the situations where a person wears glasses,\u201d the authors wrote in their study. \u201cMost of the failure modes (e.g., corresponding to extremely tilted head poses or large redirection angles involving disocclusion of the different parts of an eye) are not inherent to the model design and can be addressed by augmenting the training data with appropriate examples.\u201d\nThe authors say they plan to work on making the demo work more quickly in the future.\n\n\n\n\n\n\n\n\n\n"}
