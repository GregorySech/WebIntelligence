{"title": "This French school is using facial recognition to find out when students aren\u2019t paying attention", "content": " \nA business school in Paris will soon begin using artificial intelligence and facial analysis to determine whether students are paying attention in class. The software, called Nestor, will be used two online classes at the ESG business school beginning in September. LCA Learning, the company that created Nestor, presented the technology at an event at the United Nations in New York last week. \nThe idea, according to LCA founder Marcel Saucet, is to use the data that Nestor collects to improve the performance of both students and professors. The software uses students\u2019 webcams to analyze eye movements and facial expressions and determine whether students are paying attention to a video lecture. It then formulates quizzes based on the content covered during moments of inattentiveness. Professors would also be able to identify moments when students\u2019 attention waned, which could help to improve their teaching, Saucet says.\nAt first, the technology will only be used for students who watch lectures remotely, though Saucet hopes to eventually launch an in-class version that would send real-time notifications to students whenever they\u2019re not paying attention. Speaking to journalists during a demonstration at ESG\u2019s Paris campus last month, Saucet said the technology could vastly improve the performance of students who take massive open online courses, or MOOCs.  \n\u201cThe problem with MOOCs is that they don\u2019t work,\u201d Saucet said. \u201cIt\u2019s been 10 years that we\u2019ve been trying e-learning, and in the US it\u2019s been 25 years. And it doesn\u2019t work.\u201d\n\nA press release from the UN\u2019s World Council of Peoples, which hosted last week\u2019s event, described the launch of Nestor as the \u201cfirst AI led class,\u201d though that\u2019s not entirely accurate. The software is not capable of actually teaching a course, and it\u2019s not the first time that schools have experimented with similar technologies. The IE Business School in Madrid recently created a WOW Room (the acronym stands for \u201cWindow on the World\u201d), where professors stand before a wall of screens and lecture students who tune in from afar. Like Nestor, the system uses \u201cemotion recognition systems\u201d to measure students\u2019 attention. \nAdvocates for AI in education say the technology could be used as a digital tutor that would adapt to a student\u2019s individual needs, and help foster more effective studying habits. Such software could also help teachers by providing quantitative feedback on the effectiveness of their teaching, advocates say. Some researchers have even raised the prospect of AI acting as a \u201clifelong learning companion\u201d that would accompany students for years. \nBut AI programs rely on massive troves of personal data, and there are concerns over how such data would be treated. A personalized learning program launched in New York by InBloom, a data analytics company, collapsed in 2014 amid growing concerns over how data on students would be used and protected from hackers.  \nSaucet says Nestor won\u2019t store any of the video footage it captures and that his company has no plans to sell any other data the software collects. (His company sells its software to schools.) The data would also be encrypted and anonymized, he says. In addition to facial recognition and analysis, the software can integrate with students\u2019 calendars to suggest possible study times, and track their online behavior to pick up on patterns. If a student typically spends their weeknights watching YouTube videos, for example, Nestor could suggest that they instead spend that time studying. Saucet acknowledges, however, that it will ultimately be up to each school to decide how to treat and store such data. \n\u201cWhat\u2019s happening is being led by the technology, rather than by the learning science.\u201d\nRose Luckin, a professor at the University College London Knowledge Lab, says AI could unlock the \u201cblack box of learning\u201d by providing information on how and when learning happens. But she cautions against adopting new technologies that, while alluring, may not actually respond to critical needs.      \n\u201cI think it can have a huge impact on education,\u201d Luckin says. \u201cBut I think the problem at the moment is that what\u2019s happening is being led by the technology, rather than by the learning science, and that's problematic.\u201d \nLuckin says a program like Nestor could be useful for students who take classes remotely, since \u201cthere isn\u2019t a human there watching them,\u201d and she says substantial research has focused on determining emotions based on facial analysis. (Several companies have begun using similar technology for advertising.) But she says she\u2019s unaware of any large scale study on the educational effectiveness of such programs, and she questions the value in quizzing students on content that they weren\u2019t paying attention to.   \n\u201cA much more pedagogically sound approach would be to show the student when they are focused, and how that relates to their performance,\u201d Luckin says. \u201cSo that you're offering information back to the student that helps them to structure their work time more effectively and helps them to become a more effective learner.\u201d \nAnd while some are concerned that AI may one day replace teachers, Luckin sees the technology more as an assistant, rather than a replacement. Saucet agrees. \n\u201cHuman contact is not going to go away,\u201d he says. \u201cThere will always be professors.\u201d\n\n"}
