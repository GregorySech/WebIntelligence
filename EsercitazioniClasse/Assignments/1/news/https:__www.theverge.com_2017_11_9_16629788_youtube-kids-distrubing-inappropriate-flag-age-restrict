{"title": "YouTube says it will crack down on bizarre videos targeting children", "content": " \nEarlier this week, a report in The New York Times and a blog post on Medium drew a lot of attention to a world of strange and sometimes disturbing videos on YouTube aimed at young children. The genre, which we reported on in February of this year, makes use of popular characters from family-friendly entertainment, but it\u2019s often created with little care, and can quickly stray from innocent themes to scenes of violence or sexuality. \nIn August of this year, YouTube announced that it would no longer allow creators to monetize videos which \u201cmade inappropriate use of family friendly characters.\u201d Today it\u2019s taking another step to try and police this genre. \n\u201cWe\u2019re in the process of implementing a new policy that age restricts this content in the YouTube main app when flagged,\u201d said Juniper Downs, YouTube\u2019s director of policy. \u201cAge-restricted content is automatically not allowed in YouTube Kids.\u201d YouTube says that it\u2019s been formulating this new policy for a while, and that it\u2019s not rolling it out in direct response to the recent coverage.\nThe first line of defense for YouTube Kids are algorithmic filters. After that, there is a team of humans that review videos which have been flagged. If a video with recognizable children\u2019s characters gets flagged in YouTube\u2019s main app, which is much larger than the Kids app, it will be sent to the policy review team. YouTube says it has thousands of people working around the clock in different time zones to review flagged content. If the review finds the video is in violation of the new policy, it will be age restrictied, automatically blocking it from showing up in the Kids app. \nYouTube says it typically takes at least a few days for content to make its way from YouTube proper to YouTube Kids, and the hope is that within that window, users will flag anything potentially disturbing to children. YouTube also has a team of volunteer moderators, which it calls Contributors, looking for inappropriate content. YouTube says it will start training its review team on the new policy and it should be live within a few weeks. \nAlong with filtering content out of the Kids app, the new policy will also tweak who can see these videos on YouTube\u2019s main service. Flagged content will be age restricted, and users won\u2019t be able to see those videos if they\u2019re not logged in on accounts registered to users 18 years or older. All age-gated content is also automatically exempt from advertising. That means this new policy could put a squeeze on the booming business of crafting strange kid\u2019s content.\n\nYouTube is trying to walk a fine line between owning up to this problem and arguing that the issue is relatively minor. It says that the fraction of videos on YouTube Kids that were missed by its algorithmic filters and then flagged by users during the last 30 days amounted to just 0.005 percent of videos on the service. The company also says the reports that inappropriate videos racked up millions of views on YouTube Kids without being vetted are false, because those views came from activity on YouTube proper, which makes clear in its terms of service that it\u2019s aimed at user 13 years and older.\nIn today\u2019s policy announcement, YouTube is acknowledging the problem, and promising to police it better. It doesn\u2019t want to outright ban the use of family-friendly characters by creators who aren\u2019t the original copyright holders across all of YouTube. There is a place, the company is arguing, for satire about Peppa Pig drinking bleach, however distasteful you might find it. But YouTube is acknowledging that YouTube Kids requires even more moderation. And, the company is willing to forgo additional ad revenue \u2014 and there is a lot of money flowing through this segment of the industry \u2014 if that\u2019s what it takes to ensure YouTube Kids feels like a safe experience for families.\n"}
